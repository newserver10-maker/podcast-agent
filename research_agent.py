"""
Research Agent - YouTube ì±„ë„ì—ì„œ ìµœê·¼ ì˜ìƒ ìˆ˜ì§‘ ë° ìë§‰ ì¶”ì¶œ

ì´ì „ ë°©ì‹: Playwrightë¡œ YouTube ì±„ë„ í˜ì´ì§€ë¥¼ ìŠ¤í¬ë˜í•‘ (ë¸Œë¼ìš°ì € í•„ìš”)
ìƒˆë¡œìš´ ë°©ì‹: RSS í”¼ë“œ + youtube-transcript-api (ë¸Œë¼ìš°ì € ë¶ˆí•„ìš”)

ì™œ ë³€ê²½í–ˆëŠ”ê°€:
- Playwright ë°©ì‹ì€ ì…€ë ‰í„° ë³€ê²½ì— ì·¨ì•½í•˜ê³ , headless ëª¨ë“œì—ì„œ ë¶ˆì•ˆì •
- RSS + API ë°©ì‹ì€ ìˆœìˆ˜ HTTP í˜¸ì¶œì´ë¯€ë¡œ ì•ˆì •ì ì´ê³  ë¹ ë¦„
"""

import json
import re
import sys
import os
from datetime import datetime, timezone, timedelta
from pathlib import Path

# Windows ì½˜ì†” ì¸ì½”ë”© ë¬¸ì œ ë°©ì§€ (cp949 â†’ utf-8)
if sys.platform == "win32":
    sys.stdout.reconfigure(encoding="utf-8", errors="replace")
    sys.stderr.reconfigure(encoding="utf-8", errors="replace")

import feedparser
import requests
from youtube_transcript_api import YouTubeTranscriptApi
from youtube_transcript_api._errors import (
    TranscriptsDisabled,
    NoTranscriptFound,
    VideoUnavailable,
)

# v1.2.4: ì¸ìŠ¤í„´ìŠ¤ ê¸°ë°˜ API
ytt_api = YouTubeTranscriptApi()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ëŒ€ìƒ ì±„ë„ ì„¤ì •
# channel_idëŠ” YouTube RSS í”¼ë“œì—ì„œ í•„ìš” (í•¸ë“¤ â†’ ID ë³€í™˜)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CHANNELS = [
    {"handle": "@sosumonkey", "name": "ì†Œìˆ˜ëª½í‚¤", "channel_id": "UCC3yfxS5qC6PCwDzetUuEWg"},
    {"handle": "@orlandocampus", "name": "ì˜¬ëœë„ í‚´ ë¯¸êµ­ì£¼ì‹", "channel_id": "UCwSSqi-s0wcH6pJbH3YPZqQ"},
    {"handle": "@buiknam_tv", "name": "ë¶€ì½ë‚˜TV_ë‚´ì§‘ë§ˆë ¨ë¶€í„°ê±´ë¬¼ì£¼ê¹Œì§€", "channel_id": "UC2QeHNJFfuQWB4cy3M-745g"},
]

# ìë§‰ ìš°ì„ ìˆœìœ„: í•œêµ­ì–´ > ì˜ì–´
TRANSCRIPT_LANGUAGES = ["ko", "en"]

# ëª‡ ì‹œê°„ ì´ë‚´ ì˜ìƒì„ "ìµœê·¼"ìœ¼ë¡œ ë³¼ ê²ƒì¸ì§€
RECENT_HOURS = 24


def resolve_channel_id(handle: str) -> str | None:
    """
    YouTube í•¸ë“¤(@ì´ë¦„)ì—ì„œ channel_idë¥¼ ê°€ì ¸ì˜¨ë‹¤.
    ë°©ë²•: ì±„ë„ í˜ì´ì§€ HTMLì—ì„œ 'channel_id' ë©”íƒ€ íƒœê·¸ë¥¼ íŒŒì‹±.
    """
    url = f"https://www.youtube.com/{handle}"
    try:
        resp = requests.get(url, headers={"Accept-Language": "ko-KR"}, timeout=10)
        resp.raise_for_status()
        # HTMLì—ì„œ channel_id ì¶”ì¶œ
        match = re.search(r'"channelId":"(UC[^"]+)"', resp.text)
        if match:
            return match.group(1)
        # externalIdì—ì„œ ì‹œë„ (ìµœì‹  YouTube í˜ì´ì§€ êµ¬ì¡°)
        match = re.search(r'externalId.{0,5}(UC[a-zA-Z0-9_-]{22})', resp.text)
        if match:
            return match.group(1)
        # meta íƒœê·¸ì—ì„œë„ ì‹œë„
        match = re.search(r'<meta\s+itemprop="channelId"\s+content="(UC[^"]+)"', resp.text)
        if match:
            return match.group(1)
    except Exception as e:
        print(f"  [WARN] ì±„ë„ ID ì¡°íšŒ ì‹¤íŒ¨ ({handle}): {e}")
    return None


def get_recent_videos_from_rss(channel_id: str, channel_name: str, hours: int = RECENT_HOURS) -> list[dict]:
    """
    YouTube RSS í”¼ë“œì—ì„œ ìµœê·¼ Nì‹œê°„ ì´ë‚´ ì˜ìƒ ëª©ë¡ì„ ê°€ì ¸ì˜¨ë‹¤.
    RSS í”¼ë“œ URL: https://www.youtube.com/feeds/videos.xml?channel_id=CHANNEL_ID
    """
    feed_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"
    feed = feedparser.parse(feed_url)
    
    cutoff = datetime.now(timezone.utc) - timedelta(hours=hours)
    recent = []
    
    for entry in feed.entries[:10]:  # ìµœê·¼ 10ê°œë§Œ í™•ì¸
        # RSSì˜ published ì‹œê°„ íŒŒì‹±
        published = datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)
        
        if published >= cutoff:
            video_id = entry.yt_videoid
            recent.append({
                "title": entry.title,
                "url": f"https://www.youtube.com/watch?v={video_id}",
                "video_id": video_id,
                "published": published.isoformat(),
                "channel": channel_name,
            })
    
    return recent


def extract_transcript(video_id: str) -> str | None:
    """
    YouTube ì˜ìƒì—ì„œ ìë§‰(transcript)ì„ ì¶”ì¶œí•œë‹¤.
    í•œêµ­ì–´ > ì˜ì–´ ìˆœìœ¼ë¡œ ì‹œë„.
    v1.2.4: ì¸ìŠ¤í„´ìŠ¤ ê¸°ë°˜ fetch() ë©”ì„œë“œ ì‚¬ìš©
    """
    try:
        transcript = ytt_api.fetch(video_id, languages=TRANSCRIPT_LANGUAGES)
        # ìë§‰ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹¨
        full_text = " ".join([snippet.text for snippet in transcript.snippets])
        return full_text
    except TranscriptsDisabled:
        print(f"    [SKIP] ìë§‰ ë¹„í™œì„±í™”: {video_id}")
    except NoTranscriptFound:
        print(f"    [SKIP] ìë§‰ ì—†ìŒ: {video_id}")
    except VideoUnavailable:
        print(f"    [SKIP] ì˜ìƒ ì ‘ê·¼ ë¶ˆê°€: {video_id}")
    except Exception as e:
        print(f"    [WARN] ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    return None


def get_recent_videos_with_transcripts(hours: int = RECENT_HOURS) -> list[dict]:
    """
    ëª¨ë“  ëŒ€ìƒ ì±„ë„ì—ì„œ ìµœê·¼ ì˜ìƒì„ ìˆ˜ì§‘í•˜ê³ , ìë§‰ì„ ì¶”ì¶œí•œë‹¤.
    
    Returns:
        list[dict]: ê° ì˜ìƒì˜ ì œëª©, URL, ìë§‰ í…ìŠ¤íŠ¸ ë“±
    """
    results = []
    
    for ch in CHANNELS:
        print(f"ğŸ“¡ ì±„ë„ í™•ì¸: {ch['name']} ({ch['handle']})")
        
        # 1. ì±„ë„ ID ì¡°íšŒ
        channel_id = ch.get("channel_id")
        if not channel_id:
            channel_id = resolve_channel_id(ch["handle"])
            if not channel_id:
                print(f"  [ERROR] ì±„ë„ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {ch['handle']}")
                continue
            ch["channel_id"] = channel_id
            print(f"  ì±„ë„ ID: {channel_id}")
        
        # 2. RSSì—ì„œ ìµœê·¼ ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        videos = get_recent_videos_from_rss(channel_id, ch["name"], hours)
        print(f"  ìµœê·¼ {hours}ì‹œê°„ ë‚´ ì˜ìƒ: {len(videos)}ê°œ")
        
        # 3. ê° ì˜ìƒì—ì„œ ìë§‰ ì¶”ì¶œ
        for video in videos:
            print(f"  ğŸ“¹ {video['title']}")
            transcript = extract_transcript(video["video_id"])
            if transcript:
                video["transcript"] = transcript
                video["transcript_length"] = len(transcript)
                print(f"    âœ… ìë§‰ ì¶”ì¶œ ì™„ë£Œ ({len(transcript)}ì)")
                results.append(video)
            else:
                print(f"    âš ï¸ ìë§‰ ì—†ì´ ê±´ë„ˆëœ€")
    
    return results


def get_recent_video_urls(hours: int = RECENT_HOURS) -> list[dict]:
    """
    ëª¨ë“  ëŒ€ìƒ ì±„ë„ì—ì„œ ìµœê·¼ ì˜ìƒ URLë§Œ ìˆ˜ì§‘í•œë‹¤.
    ìë§‰ ì¶”ì¶œ ì—†ì´ URLë§Œ ê°€ì ¸ì˜¤ë¯€ë¡œ í›¨ì”¬ ë¹ ë¥´ë‹¤.
    NotebookLMì´ YouTube URLì—ì„œ ì§ì ‘ ë‚´ìš©ì„ ì²˜ë¦¬í•˜ë¯€ë¡œ ìë§‰ ë¶ˆí•„ìš”.
    
    Returns:
        list[dict]: ê° ì˜ìƒì˜ ì œëª©, URL, video_id ë“±
    """
    results = []
    
    for ch in CHANNELS:
        print(f"ğŸ“¡ ì±„ë„ í™•ì¸: {ch['name']} ({ch['handle']})")
        
        channel_id = ch.get("channel_id")
        if not channel_id:
            channel_id = resolve_channel_id(ch["handle"])
            if not channel_id:
                print(f"  [ERROR] ì±„ë„ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {ch['handle']}")
                continue
            ch["channel_id"] = channel_id
        
        videos = get_recent_videos_from_rss(channel_id, ch["name"], hours)
        print(f"  ìµœê·¼ {hours}ì‹œê°„ ë‚´ ì˜ìƒ: {len(videos)}ê°œ")
        
        for video in videos:
            print(f"  ğŸ“¹ {video['title']}")
            results.append(video)
    
    return results


if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ”¬ Research Agent ì‹œì‘")
    print("=" * 60)
    
    # URLë§Œ ìˆ˜ì§‘ (ê¸°ë³¸ ëª¨ë“œ â€” NotebookLMìš©)
    videos = get_recent_video_urls()
    
    print(f"\nâœ… ì´ {len(videos)}ê°œ ì˜ìƒ ìˆ˜ì§‘ ì™„ë£Œ")
    
    # ê²°ê³¼ ì €ì¥
    output_path = Path(__file__).parent / "recent_videos.json"
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(videos, f, indent=2, ensure_ascii=False)
    
    print(f"  ğŸ’¾ ì˜ìƒ ëª©ë¡ ì €ì¥: {output_path.name}")

